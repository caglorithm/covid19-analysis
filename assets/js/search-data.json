{
  
    
        "post0": {
            "title": "Title",
            "content": "The neural mass model . In this model, we will learn about the basic of neurolib. We will create a two-population mean-field model of exponential integrate-and-fire neurons called the aln model. We will learn how to create a Model, set some parameters and run a simulation. We will also see how we can easily access the output of each simulation. . aln - the adaptive linear-nonlinear cascade model . The adaptive linear-nonlinear (aln) cascade model is a low-dimensional population model of spiking neural networks. Mathematically, it is a dynamical system of non-linear ODEs. The dynamical variables of the system simulated in the aln model describe the average firing rate and other macroscopic variables of a randomly connected, delay-coupled network of excitatory and inhibitory adative exponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents. . Ultimately, the model is a result of various steps of model reduction starting from the Fokker-Planck equation of the AdEx neuron subject to white noise input at many steps of input means $ mu$ and variances $ sigma$. The resulting mean firing rates and mean membrane potentials are then stored in a lookup table and serve as the nonlinear firing rate transfer function, $r = Phi( mu, sigma)$. . Basic use . # change to the root directory of the project import os if os.getcwd().split(&quot;/&quot;)[-1] == &quot;examples&quot;: os.chdir(&#39;..&#39;) # This will reload all imports as soon as the code changes %load_ext autoreload %autoreload 2 . try: import matplotlib.pyplot as plt except ImportError: import sys !{sys.executable} -m pip install matplotlib import matplotlib.pyplot as plt import numpy as np import scipy # Let&#39;s import the aln model from neurolib.models.aln import ALNModel # Some useful functions are provided here import neurolib.utils.functions as func # a nice color map plt.rcParams[&#39;image.cmap&#39;] = &#39;plasma&#39; . Simulating a single aln node . To create a single node, we simply instanciate the model without any arguments. . # Create the model aln = ALNModel() # Each model comes with a set of default parameters which are are a dictionary. # Let&#39;s change the parameter that controls the duration of a simulation to 10s. aln.params[&#39;duration&#39;] = 10.0 * 1000 # For convenience, we could also use: aln.params.duration = 10.0 * 1000 # In the aln model an Ornstein-Uhlenbeck process is simulated in parallel # as the source of input noise fluctuations. Here we can set the variance # of the process. # For more info: https://en.wikipedia.org/wiki/Ornstein%E2%80%93Uhlenbeck_process # Let&#39;s add some noise. aln.params[&#39;sigma_ou&#39;] = 0.1 # Finally, we run the model aln.run() . Accessing the outputs . Accessing the outputs is straight-forward. Every model&#39;s outputs are stored in the model.outputs attribute. According to the specific name of each of the model&#39;s outputs, they can also be accessed as a key of the Model object, i.e. aln[&#39;rates_exc&#39;]. . plt.plot(aln[&#39;t&#39;], aln[&#39;rates_exc&#39;].T, lw=2, c=&#39;k&#39;) plt.xlabel(&quot;t [ms]&quot;) plt.ylabel(&quot;Rate [Hz]&quot;) plt.xlim(1000, 2000); . # Outputs are also available as an xr DataArray xr = aln.xr() print(xr.dims) # outputs can also be accessed via attributes in dot.notation print(&quot;rates_exc&quot;, aln.rates_exc) . (&#39;output&#39;, &#39;space&#39;, &#39;time&#39;) rates_exc [[0.00140945 0.00140945 0.00140945 ... 1.2305995 1.17718972 1.12310331]] . Whole-brain model . neurolib comes with some example datasets for exploring its functionality. Please be aware that these datasets are not tested and should not be used for your research, only for experimentation with the software. . A dataset for whole-brain modeling can consists of the following parts: . A structural connectivity matrix capturing the synaptic connection strengths between brain areas, often derived from DTI tractography of the whole brain. The connectome is then typically parcellated in a preferred atlas (for exapmle the AAL2 atlas) and the number of axonal fibers connecting each brain area with every other area is counted. This number serves as a indication of the synaptic coupling strengths between the areas of the brain. | A delay matrix which can be calculated from the average length of the axonal fibers connecting each brain area with another. | A set of functional data that can act as a target for model optimization. Resting-state fMRI offers an easy and fairly unbiased way for calibrating whole-brain models. EEG data could be used as well. | . We can load a Dataset by passing the name of it in the constructor. . from neurolib.utils.loadData import Dataset ds = Dataset(&quot;gw&quot;) . We now create the aln model with a structural connectivity matrix and a delay matrix. In order to achieve a good fit of the BOLD activity to the empirical data, the model has to run for quite a while. A a rule of thumb, a simulation of resting-state BOLD activity should not be shorter than 3 minutes and preferrably longer than 5 minutes real time. If the empirical recordings are for example 10 minues long, ideally, a simulation of 10 minutes would be used to compare the output of the model to the resting state recording. . aln = ALNModel(Cmat = ds.Cmat, Dmat = ds.Dmat) aln.params[&#39;duration&#39;] = 0.2*60*1000 # Info: value 0.2*60*1000 is low for testing # use 5*60*1000 for real simulation . After some optimization to the resting-state fMRI data of the dataset, we found a set of parameters that creates interesting whole-brain dynamics. We set the mean input of the excitatory and the inhibitory population to be close to the E-I limit cycle. . aln.params[&#39;mue_ext_mean&#39;] = 1.57 aln.params[&#39;mui_ext_mean&#39;] = 1.6 # We set an appropriate level of noise aln.params[&#39;sigma_ou&#39;] = 0.09 # And turn on adaptation with a low value of spike-triggered adaptation currents. aln.params[&#39;b&#39;] = 5.0 . Let&#39;s have a look what the data looks like. We can access the data of each model by calling its internal attrivbutes. Here, we plot the structural connectivity matrix by calling aln.params[&#39;Cmat&#39;] and fiber length matrix by calling aln.params[&#39;lengthMat&#39;]. Of course, we can also access the dataset using the Dataset object itself. For example the functional conencity matrices of the BOLD timeseries in the datasets are given as list with ds.FCs. . from matplotlib.colors import LogNorm fig, axs = plt.subplots(1, 3, figsize=(12,8), dpi=75) fig.subplots_adjust(wspace=0.28) im = axs[0].imshow(aln.params[&#39;Cmat&#39;], norm=LogNorm(vmin=10e-5, vmax=np.max(aln.params[&#39;Cmat&#39;]))) axs[0].set_title(&quot;Cmat&quot;) fig.colorbar(im, ax=axs[0],fraction=0.046, pad=0.04) im = axs[1].imshow(aln.params[&#39;lengthMat&#39;], cmap=&#39;inferno&#39;) axs[1].set_title(&quot;Dmat&quot;) fig.colorbar(im, ax=axs[1],fraction=0.046, pad=0.04) im = axs[2].imshow(ds.FCs[0], cmap=&#39;inferno&#39;) axs[2].set_title(&quot;Empirical FC&quot;) fig.colorbar(im, ax=axs[2],fraction=0.046, pad=0.04) . &lt;matplotlib.colorbar.Colorbar at 0x12c0ac5c0&gt; . Run model . We run the model with bold simulation by using bold=True. This simulates the Balloon-Windkessel BOLD model in parallel to the neural population model in order to estimate the blood oxigen levels of the underlying neural activity. The output of the bold model can be used to compare the simulated data to empirical fMRI data (resting-state fMRI for example). . To save (a lot of) RAM, we can run the simulation in chunkwise mode. In this mode, the model will be simulated for a length of chunksize steps (not time in ms, but actual integration steps!), and the output of that chunk will be used to automatically reinitiate the model with the appropriate initial conditions. This allows for a serial continuation of the model without having to store all the data in memory and is particularly useful for very long and many parallel simulations. . aln.run(chunkwise=True, chunksize = 100000, bold=True) . Results . The outputs of the model can be accessed using the attribute model.outputs . aln.outputs . {&#39;t&#39;: array([0.000e+00, 1.000e-01, 2.000e-01, ..., 9.598e+02, 9.599e+02, 9.600e+02]), &#39;rates_exc&#39;: array([[0.00835719, 0.00840018, 0.008441 , ..., 0.07789972, 0.07678947, 0.07575822]]), &#39;rates_inh&#39;: array([[6.67987791, 6.74212832, 6.82498266, ..., 9.74761859, 9.76436539, 9.75417725]]), &#39;BOLD&#39;: {&#39;t&#39;: array([1.00000e-01, 2.00010e+03, 4.00010e+03, 6.00010e+03, 8.00010e+03, 1.00001e+04, 1.20001e+04, 1.40001e+04, 1.60001e+04, 1.80001e+04, 2.00001e+04, 2.20001e+04, 2.40001e+04]), &#39;BOLD&#39;: array([[1.37324205e-10, 2.32894551e-02, 2.52461497e-02, 1.57354848e-02, 9.56109432e-03, 1.05825534e-02, 1.12229272e-02, 1.22928019e-02, 1.53881680e-02, 1.50792887e-02, 1.27970412e-02, 1.30106312e-02, 1.40587017e-02]])}} . For convenience, they can also be accessed directly using attributes of the model with the outputs name, like aln.rates_exc. The outputs are also available as xr DataArrays as aln.xr(). . The since we used bold=True to simulate BOLD, we can also access aln.BOLD.BOLD for the actual BOLD activity, and aln.BOLD.t for the time steps of the BOLD simulation (which are downsampled to 0.5 Hz by default). . Plot simulated activity . # Plot functional connectivity and BOLD timeseries (z-scored) fig, axs = plt.subplots(1, 2, figsize=(6, 2), dpi=75, gridspec_kw={&#39;width_ratios&#39; : [1, 2]}) axs[0].imshow(func.fc(aln.BOLD.BOLD[:, 5:])) axs[1].imshow(scipy.stats.mstats.zscore(aln.BOLD.BOLD[:, aln.BOLD.t_BOLD&gt;10000], axis=1), aspect=&#39;auto&#39;, extent=[aln.BOLD.t_BOLD[aln.BOLD.t_BOLD&gt;10000][0], aln.BOLD.t_BOLD[-1], 0, aln.params[&#39;N&#39;]]); axs[0].set_title(&quot;FC&quot;) axs[0].set_xlabel(&quot;Node&quot;) axs[0].set_ylabel(&quot;Node&quot;) axs[1].set_xlabel(&quot;t [ms]&quot;) # the results of the model are also accesible through an xarray DataArray fig, axs = plt.subplots(1, 1, figsize=(6, 2), dpi=75) plt.plot(aln.xr().time, aln.xr().loc[&#39;rates_exc&#39;].T); . Correlation of simulated BOLD to empirical data . We can compute the element-wise Pearson correlation of the functional connectivity matrices of the simulated data to the empirical data to estimate how well the model captures the inter-areal BOLD correlations found in empirical resting-state recordings. . scores = [func.matrix_correlation(func.fc(aln.BOLD.BOLD[:, 5:]), fcemp) for fcemp in ds.FCs] print(&quot;Correlation per subject:&quot;, [f&quot;{s:.2}&quot; for s in scores]) print(f&quot;Mean FC/FC correlation: {np.mean(scores):.2}&quot;) . Correlation per subject: [&#39;0.52&#39;, &#39;0.54&#39;, &#39;0.67&#39;, &#39;0.49&#39;, &#39;0.69&#39;] Mean FC/FC correlation: 0.58 .",
            "url": "https://caglorithm.github.io/notebooks/2020/04/10/neurolib-example.html",
            "relUrl": "/2020/04/10/neurolib-example.html",
            "date": " • Apr 10, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19 Fatality rates",
            "content": "Last build 10.04.20 00:17:46 . Cummulative confirmed cases per deaths . The fatality rate is calculated as the cumulative number of confirmed cases divided by the cumulative number of deaths. . click the country label that you want to highlight. Shift + click to compare different countries. .",
            "url": "https://caglorithm.github.io/notebooks/covid-fatality-rates/",
            "relUrl": "/covid-fatality-rates/",
            "date": " • Mar 21, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "COVID-19 Confirmed Cases vs. Deaths",
            "content": "Last build 10.04.20 00:16:20 . Estimated time of infection vs. confirmed infections . Following the ideas from Tomas Pueyo&#39;s Medium post &quot;Coronavirus: Why You Must Act Now&quot; [1], we assume the average time from infection to death at 23 days [2]. The data is pulled from the COVID-19 Data Repository by Johns Hopkins CSSE [3] every hour. Countries with a minimnum of 1000 confirmed cases and 40 confirmed deaths are included in this analysis. . The time from infection to death is equal to the incubation period plus the time from symptoms to death. This is used to estimate the time of the infections that lead to the observed deaths. We take the last fatality rate per country (total_cases/total_deaths) to estimate the number of infections that are responsible for the observed deaths. . In the figures below, you can observe successive waves of infections (dashed), detections (black) and deaths (red) for each country. The upper panel shows the absolute number of events. The dashed lines show the estimated number of infections. The lower panel shows the normalized number of events. Here the temporal delay between the waves and the relative change between each other can be observed. . [1] https://medium.com/@tomaspueyo/coronavirus-act-today-or-people-will-die-f4d3d9cd99ca . [2] https://github.com/midas-network/COVID-19/tree/master/parameter_estimates/2019_novel_coronavirus . [3] https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series . Ahead of the curve . Some countries start testing the population earlier in the outbreak than others. The time delay between the wave of deaths and the wave of confirmed cases is indicative for how early a country is detecting new cases ahead of the increase of deaths. Earlier detection means a better chances for successful isolation of an infected person and treatment of the desease. . We measure the distance of the maximum of cumulative deaths and new deaths to the number of infections to estimate the progression of the infection across countries. . If, in the early phase of the infection wave, the number of deaths rises faster than the number of confirmed cases, the distance drops, indicating that . A comparison of countries with respect to their mean time for reponse is presented below. . To determine the above values, we plot the number of confirmed cases (solid black lines) and the number of deaths (dashed black lines). From this, we measure the distance of the day of maximum deaths (dashed red lines) to the day of confirmed cases at this y-value. . The distance is indicative for how fast the humber of confirmed cases increases comapred to the increase of the number of deaths. .",
            "url": "https://caglorithm.github.io/notebooks/covid-cases-to-deaths/",
            "relUrl": "/covid-cases-to-deaths/",
            "date": " • Mar 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "COVID-19 Logistic function fit",
            "content": "Italy China Iran Spain France US United Kingdom South Korea Netherlands Germany Switzerland . Text(0, 0.5, &#39;Cases&#39;) . Days since 10th case cases country 0 4 41.849156 Germany 1 5 56.486504 Germany 2 6 76.241614 Germany 3 7 102.902313 Germany 4 8 138.879728 Germany .. ... ... ... 58 7 216.220404 United Kingdom 59 8 291.844940 United Kingdom 60 9 393.909243 United Kingdom 61 10 531.648593 United Kingdom 62 11 717.517076 United Kingdom [63 rows x 3 columns] .",
            "url": "https://caglorithm.github.io/notebooks/covid-logistic-fit/",
            "relUrl": "/covid-logistic-fit/",
            "date": " • Mar 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://caglorithm.github.io/notebooks/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}